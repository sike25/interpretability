## The Mythos of Model Interpretability

**Zachary C. Lipton, 2017**

This paper 

Paper: https://arxiv.org/pdf/1606.03490

### 1. Introduction


### 2. Desiderata of Interpretability Research

**2.1. Trust**


**2.2. Causality**

**2.3. Transferability**

**2.4. Informativeness**

**2.5. Fair and Ethical Decision-Making**


### 3. Properties of Interpretable Models

**3.1. Transparency**

3.1.1. SIMULATABILITY

3.1.2. DECOMPOSABILITY

3.1.3. ALGORITHMIC TRANSPARENCY

**3.2. Post-hoc Interpretability**

3.2.1. TEXT EXPLANATIONS

3.2.2. VISUALIZATION

3.2.3. LOCAL EXPLANATIONS

3.2.4. EXPLANATION BY EXAMPLE

### 4. Discussion

**4.1. Linear models are not strictly more interpretable than deep neural networks**

**4.2. Claims about interpretability must be qualified**

**4.3. In some cases, transparency may be at odds with the broader objectives of AI**

**4.4. Post-hoc interpretations can potentially mislead**

**4.5. Future Work**

### 5. Contributions

---

### Reflection      

**What are the strengths?** 
1. 

**What are the weaknesses?**      
1. 

**New Terms**
1. 
