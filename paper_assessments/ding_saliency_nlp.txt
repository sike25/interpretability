Ding, Saliency-driven Word Alignment Interpretation for Neural Machine Translation

What is the main problem with attention-based word alignment in Neural Machine Translation (NMT), as discussed in the paper?
How does the paper demonstrate that saliency-driven methods can provide more accurate word alignments than traditional attention-based methods?
Describe the evaluation methods used to assess the quality of word alignments generated by the proposed saliency-driven methods.
What is the difference between "force decoding" and "free decoding" evaluations mentioned in the paper?
Explain the concept of "SmoothGrad" and its significance in the context of this study.
How do the authors claim that their method is model-agnostic? Provide details from the paper supporting this claim.
Discuss the impact of saliency methods on NMT models' interpretability according to the findings presented.
Compare and contrast the results of the saliency-driven methods with traditional models like GIZA++ and fast-align.
What are the limitations of interpreting attention weights as word alignments, as highlighted by the paper?
Based on the paper, how could the proposed saliency-driven methods influence future developments in NMT and word alignment interpretation?