{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wid4jR9fWdjY"
      },
      "source": [
        "# Colab dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ir3IeoyFWdjb"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
        "pip install ninja\n",
        "git clone https://github.com/SIDN-IAP/interactivity.git tutorial_code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9ICF8bTWdjc"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab, sys, torch\n",
        "    sys.path.append('/content/tutorial_code')\n",
        "    print(\"GPU available\" if torch.cuda.is_available()\n",
        "          else \"Change runtime type to include a GPU.\")\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NAYBLioWdjd"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sh-8z7H3Wdjd"
      },
      "outputs": [],
      "source": [
        "from netdissect import nethook, setting, renormalize, zdataset, paintwidget, labwidget, show, imgviz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpXJNiEZWdjd"
      },
      "source": [
        "# Load a GAN generator\n",
        "\n",
        "In this exercise, our goal will be to interact\n",
        "directly with the GAN.\n",
        "\n",
        "Here is an example of loading a G, getting a random Z vector, and then showing the result of running G(Z)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gW5aiBRjWdje"
      },
      "outputs": [],
      "source": [
        "# Load a generator, and paint random image number 20 in a widget.\n",
        "G = nethook.InstrumentedModel(setting.load_proggan('church')).cuda()\n",
        "zsamp = zdataset.z_sample_for_model(G, 1000).cuda()\n",
        "\n",
        "my_z = zsamp[10] # Pick some z from our sample\n",
        "my_imgdata = G(my_z[None])[0] # Run G on a batch with just this z\n",
        "\n",
        "# Show the result as an image\n",
        "show(renormalize.as_image(my_imgdata))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asp9Qlp3Wdje"
      },
      "source": [
        "# Exercise 1: Collect GAN internal activations\n",
        "\n",
        "The following code inspects the internal activations of the gan by retaining its internal layer5 while running it.\n",
        "\n",
        "The variable `activations` is a tensor containing 131072 numbers, which is too big to understand by just directly looking at the numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9OUGQxNWdje"
      },
      "outputs": [],
      "source": [
        "PROBE_IMGNUM = 13\n",
        "probe_z = zsamp[PROBE_IMGNUM][None].cuda()\n",
        "\n",
        "LAYERNAME = 'layer5'\n",
        "G.retain_layer(LAYERNAME)\n",
        "G(probe_z)\n",
        "activations = G.retained_layer(LAYERNAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4wiXWYXWdjf"
      },
      "source": [
        "We can visualize some of the activations directly by building static visualizations.  The following code just sorts through the units and visualizes one of the highest-activating ones.\n",
        "\n",
        "Our next step will be to add interactivity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpRuLXO9Wdjf"
      },
      "outputs": [],
      "source": [
        "UNIT_NUMBER = 365\n",
        "print('Highest-activating units:',\n",
        "      activations.max(3)[0].max(2)[0].sort(1, descending=True)[1][0,:10].tolist())\n",
        "iv = imgviz.ImageVisualizer(256)\n",
        "show(['Unit 6', iv.heatmap(activations, (0, 6))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXy0eqNjWdjf"
      },
      "source": [
        "**Exercise 1**:\n",
        "   1. How many numbers are contained in the `activations` tensor?  Use `activations.shape` to see its dimensions.\n",
        "   2. Change the visualization above to visualize other units like 221, 384, or 310.  How do you think these behave on other images?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ-cJtymWdjf"
      },
      "source": [
        "# Exercise 2: Create a widget to explore by region\n",
        "\n",
        "It can be hard to understand the representation by just looking the data by-unit.\n",
        "\n",
        "Instead, let's look by-region.  The following code uses a PaintWidget\n",
        "that displays an image and also collects a `mask` that can be provided by the user.\n",
        "\n",
        "The key idea is that `prober.on('mask', probe_changed)` causes the function `probe_changed`\n",
        "to be executed whenever the `mask` changes.\n",
        "\n",
        "**Exercise 2**:\n",
        "  1. Run the code and interact with the widget.\n",
        "  2. Change the line where mean is computed (about line 13) to compute\n",
        "     the (positive) maximum of each channel within the selected\n",
        "     area, instead of the weighted mean.\n",
        "\n",
        "Hint: in pytorch, max(dim) returns a pair of (maxval, maxindex).  You want maxval, so `.max(2)[0].max(1)[0]` will take the maximum over the 2nd and 1st dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odQyAd1cWdjg"
      },
      "outputs": [],
      "source": [
        "SELECTED_UNITS = []\n",
        "SELECTED_VALUES = []\n",
        "\n",
        "# Now let's explore the data interactively.\n",
        "prober = paintwidget.PaintWidget(oneshot=True)\n",
        "prober.image = renormalize.as_url(G(zsamp[PROBE_IMGNUM][None])[0])\n",
        "activations = G.retained_layer(LAYERNAME)\n",
        "output_div = labwidget.Div('Click and drag above')\n",
        "\n",
        "def probe_changed(c):\n",
        "    area = renormalize.from_url(prober.mask, target='pt', size=activations.shape[2:])[0]\n",
        "    if area.sum() <= 0.0: return\n",
        "    # TODO: exercise 2 - change the code below to collect unitwise max\n",
        "    mean = (activations.cpu()[0] * area[None]).sum(2).sum(1) / area.sum()\n",
        "    value, order = mean.sort(0, descending=True)\n",
        "    maxval = (activations.cpu()[0] * area[None]).max(2)[0].max(1)[0]\n",
        "    value, order = maxval.sort(0, descending=True)\n",
        "    global SELECTED_UNITS, SELECTED_VALUES\n",
        "    SELECTED_UNITS = [o.item() for o in order[:10]]\n",
        "    SELECTED_VALUES = [v.item() for v in value[:10]]\n",
        "    output_div.clear()\n",
        "    output_div.print('SELECTED_UNITS:', SELECTED_UNITS)\n",
        "    output_div.print('SELECTED_VALUES:', [float('%.2f' % v) for v in SELECTED_VALUES])\n",
        "prober.on('mask', probe_changed)\n",
        "\n",
        "show(prober)\n",
        "show(output_div)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APeCb012Wdjg"
      },
      "source": [
        "# Exercise 3: Create a way to intervene by region\n",
        "\n",
        "Now instead of just exploring activations, let's modify them.\n",
        "\n",
        "The following code adds the SELECTED_VALUES to the SELECTED_UNITS\n",
        "image just in the area where you paint.  Read the code carefully.\n",
        "\n",
        "**Exercise 3**: Run the widget and experiment with painting rules.  The widget depends on SELECTED_VALUES and SELECTED_UNITS from running Exercise 3.\n",
        "   1. Can you find SELECTED_UNITS that allow doors to be drawn?  Try probing above using PROBE_IMGNUM of 13 and probing for the active units of the door.\n",
        "   2. Can you now use these units to draw doors in an image?  Try drawing in CANVAS_IMGNUM 70.  Where can doors be drawn?  Are there places that a door cannot  be drawn?\n",
        "   3. Now try changing images and regions and units.  Can you draw trees?  Grass?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "OoCxB8b9Wdjg"
      },
      "outputs": [],
      "source": [
        "CANVAS_IMGNUM = 70\n",
        "\n",
        "import torch\n",
        "\n",
        "G.remove_edits()\n",
        "canvas_z = zsamp[CANVAS_IMGNUM][None].cuda()\n",
        "canvas = paintwidget.PaintWidget(\n",
        "    image=renormalize.as_url(G(canvas_z)[0]),\n",
        "    oneshot=True\n",
        ")\n",
        "\n",
        "def canvas_changed(c):\n",
        "    global SELECTED_UNITS, SELECTED_VALUES\n",
        "    if not canvas.mask: return\n",
        "    area = renormalize.from_url(canvas.mask, target='pt', size=activations.shape[2:])[0]\n",
        "    def editrule(x, imodel, **buffers):\n",
        "        x[:,SELECTED_UNITS] += (area[None] * torch.Tensor(SELECTED_VALUES)[:,None,None]).to(x.device)\n",
        "        return x\n",
        "    G.edit_layer(LAYERNAME, rule=editrule)\n",
        "    canvas.image = renormalize.as_url(G(canvas_z)[0])\n",
        "    G.remove_edits()\n",
        "canvas.on('mask', canvas_changed)\n",
        "canvas.brushsize=10\n",
        "show([canvas])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}