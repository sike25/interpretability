{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "probing_exercise.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYMMrtphqpgk"
      },
      "source": [
        "# Imports and path setup\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkzRe66H3iVW",
        "outputId": "48e28359-28ed-4ed0-b4ff-d7237778434f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "source": [
        "!git clone https://github.com/SIDN-IAP/global-model-repr.git tutorial_code\n",
        "!pip install transformers==2.1\n",
        "!pip install spacy ftfy==4.4.3\n",
        "!python -m spacy download en\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import numpy as np\n",
        "import sys\n",
        "# sys.path.append('global-model-repr/')\n",
        "sys.path.append('/content/tutorial_code')\n",
        "# sys.path.append('..')\n",
        "from probing.utils import get_sentence_repr, get_model_and_tokenizer, get_pos_data\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    print(\"Change runtime type to include a GPU.\")\n",
        "    device = torch.device('cpu')\n",
        "print(\"device:\", device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'tutorial_code' already exists and is not an empty directory.\n",
            "Requirement already satisfied: transformers==2.1 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.1) (1.10.47)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.1) (1.17.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers==2.1) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==2.1) (0.0.38)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers==2.1) (0.1.85)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.1) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers==2.1) (4.28.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.1) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.1) (1.13.47)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.1) (0.2.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.1) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.1) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.1) (1.12.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1) (2.8)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers==2.1) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers==2.1) (0.15.2)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.1.9)\n",
            "Requirement already satisfied: ftfy==4.4.3 in /usr/local/lib/python3.6/dist-packages (4.4.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.21.0)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.17.5)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.0.8)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.1)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy==4.4.3) (0.1.8)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.6/dist-packages (from ftfy==4.4.3) (1.0.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.8->spacy) (4.28.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from html5lib->ftfy==4.4.3) (1.12.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from html5lib->ftfy==4.4.3) (0.5.1)\n",
            "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxaHPQIG3iVf"
      },
      "source": [
        "# Get data for part-of-speech tagging\n",
        "A probing experiment requires supervised data with linguistic annotation for the property we wish to study. We will use part-of-speech (POS) tagging, a classical problem in NLP. We will use (a portion of) the English Web dependency treebank from the Universal Dependencies project (https://universaldependencies.org/). The dataset comes with POS information, morphological features (tense, gender, number, etc.), and dependency labels (subject, object, etc.), so it can be used to stufy various aspects of language.\n",
        "\n",
        "In this exercise, we will use the POS information, available via `get_pos_data`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0-xo6-q3iVg",
        "outputId": "76a45faa-314a-42b2-e66e-7b7d4acb0052",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_sentences, train_labels, test_sentences, test_labels, _, _, label2index = get_pos_data(\"/content/tutorial_code/probing\", frac=0.1)\n",
        "# train_sentences, train_labels, test_sentences, test_labels, _, _, label2index = get_pos_data(\"../probing\", frac=0.1)\n",
        "num_labels = len(label2index)\n",
        "print(\"Training sentences:\", len(train_sentences), \"Test sentences:\", len(test_sentences))\n",
        "print(\"Unique labels:\", num_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training sentences: 1254 Test sentences: 208\n",
            "Unique labels: 17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keg_tLaD3iVk"
      },
      "source": [
        "# Set up model\n",
        "A probing experiment also requires a probing model, also known as an auxiliary classifier. Here we define a simple linear classifier, which takes a word representation as input and applies a linear transformation to map it to the label space.\n",
        "\n",
        "We also need a pre-model deep neural network to study. We will use the popular BERT model (https://www.aclweb.org/anthology/N19-1423.pdf), available via the HuggingFace Transformers library (https://huggingface.co/transformers/).  The library provides a number of other models that you can easily experiment with thanks to the unified API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXSLHwPJ3iVl",
        "outputId": "6b1c0b1a-283b-4ea5-dd95-c6764924e6f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "class Classifier(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.linear(input)\n",
        "        return output\n",
        "\n",
        "\n",
        "class NonlinearClassifier(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        NotImplementedError\n",
        "\n",
        "    def forward(self, input):\n",
        "        NotImplementedError\n",
        "\n",
        "\n",
        "def build_classifier(emb_dim, num_labels, device='cpu'):\n",
        "\n",
        "    classifier = Classifier(emb_dim, num_labels).to(device)\n",
        "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "    optimizer = torch.optim.Adam(classifier.parameters())\n",
        "\n",
        "    return classifier, criterion, optimizer\n",
        "\n",
        "\n",
        "def build_nonlinear_classifier(emb_dim, num_labels, device='cpu'):\n",
        "\n",
        "    classifier = NonlinearClassifier(emb_dim, num_labels).to(device)\n",
        "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "    optimizer = torch.optim.Adam(classifier.parameters())\n",
        "\n",
        "    return classifier, criterion, optimizer\n",
        "\n",
        "\n",
        "model_name = 'bert-base-cased'\n",
        "# get model and tokenizer from Transformers\n",
        "model, tokenizer, sep, emb_dim = get_model_and_tokenizer(model_name, device)\n",
        "# build classifier\n",
        "classifier, criterion, optimizer = build_classifier(emb_dim, num_labels, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:00<00:00, 214127.74B/s]\n",
            "100%|██████████| 435779157/435779157 [00:05<00:00, 79252657.99B/s]\n",
            "100%|██████████| 213450/213450 [00:00<00:00, 6013758.14B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuLxynuc3iVp",
        "outputId": "b5733521-3402-4eba-8b4d-c2861edc616a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 768)\n",
            "    (token_type_embeddings): Embedding(2, 768)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (2): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (3): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (4): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (5): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (6): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (7): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (8): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (9): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (10): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (11): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpNO3Ida3iVs",
        "outputId": "62557085-668f-4b4a-94fa-d4e3ce54b204",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(classifier)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classifier(\n",
            "  (linear): Linear(in_features=768, out_features=17, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KluH35v3iVv"
      },
      "source": [
        "# Train\n",
        "Given a pre-trained model, a probing classifier, and supervised linguistic annotations, we can run a probing experiment. First, we'll define a training function that trains the classifier on the linguistic annotations. This is a simple implementation, but one could implement various checks like early stopping on a development set, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Q_On99u3iVx"
      },
      "source": [
        "def train(num_epochs, train_representations, train_labels,\n",
        "          model, tokenizer, sep, model_name, device,\n",
        "          classifier, criterion, optimizer, batch_size=32):\n",
        "\n",
        "    num_total = train_representations.shape[0]\n",
        "    for i in range(num_epochs):\n",
        "        total_loss = 0.\n",
        "        num_correct = 0.\n",
        "        for batch in range(0, num_total, batch_size):\n",
        "            batch_repr = train_representations[batch: batch+batch_size]\n",
        "            batch_labels = train_labels[batch: batch+batch_size]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            out = classifier(batch_repr)\n",
        "            pred = out.max(1)[1]\n",
        "            num_correct += pred.long().eq(batch_labels.long()).cpu().sum().item()\n",
        "            loss = criterion(out, batch_labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "#         print('Training epoch: {}, loss: {}, accuracy: {}'.format(i, total_loss/num_total, num_correct/num_total))\n",
        "    return total_loss/num_total, num_correct/num_total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y8Rge5S3iV0"
      },
      "source": [
        "# Evaluate\n",
        "Given the trained classifier, we'll evaluate its performance on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi0fG0vg3iV1"
      },
      "source": [
        "def evaluate(test_representations, test_labels,\n",
        "             model, tokenizer, sep, model_name, device,\n",
        "             classifier, criterion, batch_size=32):\n",
        "\n",
        "    num_correct = 0.\n",
        "    num_total = test_representations.shape[0]\n",
        "    total_loss = 0.\n",
        "    with torch.no_grad():\n",
        "        for batch in range(0, num_total, batch_size):\n",
        "            batch_repr = test_representations[batch: batch+batch_size]\n",
        "            batch_labels = test_labels[batch: batch+batch_size]\n",
        "\n",
        "            out = classifier(batch_repr)\n",
        "            pred = out.max(1)[1]\n",
        "            num_correct += pred.long().eq(batch_labels.long()).cpu().sum().item()\n",
        "            total_loss += criterion(out, batch_labels)\n",
        "\n",
        "#     print('Testing loss: {}, accuracy: {}'.format(total_loss/num_total, num_correct/num_total))\n",
        "    return total_loss/num_total, num_correct/num_total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT6l9zXlWv3_"
      },
      "source": [
        "# Generate representations with pretrained model\n",
        "Here we collect representations from the pre-trained model. We also apply a few data transformations for convenience.\n",
        "The end result is `train_sentence_representations`, a list of tensors, where each tensor has representations from one layer in the deep model. Each tensor has dimensions num_word in the corpus x representation dimensionality.\n",
        "\n",
        "Note: The function `get_sentence_repr` hides details about model selection and tokenization that are not important for our purposes, but if you want to experiment with other models you may need to change its behavior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsDgYtC2Wv4B"
      },
      "source": [
        "# top-level list: sentences, second-level lists: layers, third-level tensors of num_words x representation_dim\n",
        "train_sentence_representations = [get_sentence_repr(sentence, model, tokenizer, sep, model_name, device)\n",
        "                                  for sentence in train_sentences]\n",
        "test_sentence_representations = [get_sentence_repr(sentence, model, tokenizer, sep, model_name, device)\n",
        "                                  for sentence in test_sentences]\n",
        "\n",
        "# top-level list: layers, second-level lists: sentences\n",
        "train_sentence_representations = [list(l) for l in zip(*train_sentence_representations)]\n",
        "test_sentence_representations = [list(l) for l in zip(*test_sentence_representations)]\n",
        "\n",
        "# concatenate all word represenations\n",
        "train_representations_all = [torch.tensor(np.concatenate(train_layer_representations, 0)).to(device) for train_layer_representations in train_sentence_representations]\n",
        "test_representations_all = [torch.tensor(np.concatenate(test_layer_representations, 0)).to(device) for test_layer_representations in test_sentence_representations]\n",
        "# concatenate all labels\n",
        "train_labels_all = torch.tensor(np.concatenate(train_labels, 0)).to(device)\n",
        "test_labels_all = torch.tensor(np.concatenate(test_labels, 0)).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIBpbUIv3iV4"
      },
      "source": [
        "# Experiment 1: Evaluate representation for POS quality\n",
        "In this experiment, we train and evaluate a classifier on the top-level representations of BERT on the task of POS tagging. The test accuracy can be thought of as a measure of the quality of the representations for the POS property."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-Hsz50R3iV5",
        "outputId": "6cb2d1f5-7195-4cec-d954-e8f476e1fff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Take final layer representations\n",
        "train_representations = train_representations_all[-1]\n",
        "test_representations = test_representations_all[-1]\n",
        "\n",
        "# train\n",
        "train_loss, train_accuracy = train(10, train_representations, train_labels_all,\n",
        "          model, tokenizer, sep, model_name, device,\n",
        "          classifier, criterion, optimizer)\n",
        "# test\n",
        "test_loss, test_accuracy = evaluate(test_representations, test_labels_all,\n",
        "         model, tokenizer, sep, model_name, device,\n",
        "         classifier, criterion)\n",
        "print(\"Train accuracy: {}, Test accuracy: {}\".format(train_accuracy, test_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 0.9267587893157485, Test accuracy: 0.9175143741707209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RncHqDF3iV8"
      },
      "source": [
        "# Experiment 2: Compare representation quality across layers\n",
        "One of the major questions in neural network interpretability is how information is organized in different parts of the deep model, such as its layers.\n",
        "\n",
        "**TODO**: Train and evaluate a separate classifier per each layer. Print the test accuracies from all layers. You may also want to store the accuracites in a list `test_accs`, as this will come in handly later.\n",
        "\n",
        "\n",
        "Notice the test accuracy results for this task, and how deeper is not always better in this case.\n",
        "\n",
        "\n",
        "**Hints**: You can get the number of layers via `len(train_representations_all)`. Then, loop over layers and get the representations for layer `l` using `train_representation_all[l]` and `test_representations_all[l]`. Remember to build a new classifier for every such experiment using `build_classifier`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYqr1lX93iV9"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqkxu9xq3iWB"
      },
      "source": [
        "# Experiment 3: Non-linear classifier\n",
        "Does the probing accuracy depend on the probing model? We have previously trained a linear probing classifier. Next we will train a non-linear classifier with one hidden layer.\n",
        "\n",
        "**TODO**: Implement the `__init__` and `forward` methods in the `NonlinearClassifier` class above. Then, repeat the layer-wise probing experiment, this time building a non-linear classifier using `build_nonlinear_classifier`.\n",
        "As before, store the accuracies in a list `test_accs`.\n",
        "\n",
        "Does the layer-wise pattern change with a different probing model? What does this tell us about the information encoded in the model's internal representations?\n",
        "\n",
        "**Hints**: It is enough to use a one-hidden layer fully-connected classifier, where the number of hidden units is equal to the input dimensionality. However, you may experiment with other classifiers if you wish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sML_JwTh3iWC",
        "scrolled": true
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wiAVNq0G4ei"
      },
      "source": [
        "# Experiment 4: Control labels\n",
        "\n",
        "In this experiment we test to see how much of the good performance from Experiments 2 and 3 actually come from things the pretrained model learned, and how much of it just comes from the probe model. To test this, we use a method from Hewitt and Liang (https://arxiv.org/pdf/1909.03368.pdf). We make a <i>control task</i> which is unrelated to the POS task and do the same probing procedure on the control task. We then measure the <i>selectivity</i> of layers; the difference between their probed accuracy on the POS task and on the control task. If a layer has learned substantial things about the POS task in particular, it should be much better at the POS task than the control task; i.e. it should have high selectivity.\n",
        "\n",
        "Following Hewitt and Liang, we use the following control task for POS tagging. Each word identity will be assigned a random POS tag, with the distribution of POS tags weighted according to their actual appearance. Each word identity will always have the same tag every time it appears. We then train and test the layers on predicting this tag from the embedding. Note that this tag is a deterministic function of the word identity, so high selectivity means the embedding actually has forgotten something about the word identity.\n",
        "\n",
        "**TODO**: the code below provides control train and test labels, `control_train_labels` and `control_test_labels`. Use these to run another probing experiment with the non-linear classifier and record the resulting test accuracies in a new list, `control_test_accs`. Then, calculate the selectivity score at every layer as the differenence between the accuracy on the POS task and the accuracy on the control task.\n",
        "\n",
        "How are the selectivity results different from the previous accuracy results? What does this tell us about the model's internal representations?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S30miOQ3iWF"
      },
      "source": [
        "import random\n",
        "\n",
        "vocabulary = set(\n",
        "    word\n",
        "      for sentence in (train_sentences + test_sentences)\n",
        "      for word in sentence\n",
        ")\n",
        "all_labels = train_labels_all.tolist()\n",
        "\n",
        "# for each word identity, choose a random label, weighted according\n",
        "# to how often the labels actually appear\n",
        "control_map = {word: random.choice(all_labels) for word in vocabulary}\n",
        "\n",
        "# assign each word the label according to its identity\n",
        "control_train_labels = [torch.tensor([control_map[word] for word in sentence]) for sentence in train_sentences]\n",
        "control_test_labels = [torch.tensor([control_map[word] for word in sentence]) for sentence in test_sentences]\n",
        "control_train_labels = torch.tensor(np.concatenate(control_train_labels, 0)).to(device)\n",
        "control_test_labels = torch.tensor(np.concatenate(control_test_labels, 0)).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZukN_X9k9_z4"
      },
      "source": [
        "# Train and evaluate a classifier on the control task at every layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9vkW8AFnNL3"
      },
      "source": [
        "# Calculate the selectivity score per layer"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}