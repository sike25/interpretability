{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "probing_exercise.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYMMrtphqpgk"
      },
      "source": [
        "# Imports and path setup\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkzRe66H3iVW",
        "outputId": "621d3a30-5784-473c-83de-cea23c486868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git clone https://github.com/SIDN-IAP/global-model-repr.git tutorial_code\n",
        "!pip install transformers==2.1\n",
        "!pip install spacy ftfy==4.4.3\n",
        "!python -m spacy download en\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import numpy as np\n",
        "import sys\n",
        "# sys.path.append('global-model-repr/')\n",
        "sys.path.append('/content/tutorial_code')\n",
        "# sys.path.append('..')\n",
        "from probing.utils import get_sentence_repr, get_model_and_tokenizer, get_pos_data\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    print(\"Change runtime type to include a GPU.\")\n",
        "    device = torch.device('cpu')\n",
        "print(\"device:\", device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tutorial_code'...\n",
            "remote: Enumerating objects: 277, done.\u001b[K\n",
            "remote: Counting objects: 100% (277/277), done.\u001b[K\n",
            "remote: Compressing objects: 100% (205/205), done.\u001b[K\n",
            "remote: Total 277 (delta 131), reused 201 (delta 70), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (277/277), 1.19 MiB | 2.45 MiB/s, done.\n",
            "Resolving deltas: 100% (131/131), done.\n",
            "Collecting transformers==2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/e5/4fb8a6215608c4036b6dd16613268a4b8958c20e4249d141e621e7f2e146/transformers-2.1.0-py3-none-any.whl (313kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.1) (1.17.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 21.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers==2.1) (4.28.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.1) (1.10.47)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 47.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers==2.1) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.1) (2.21.0)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.1) (1.13.47)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.1) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.1) (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.1) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.1) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.1) (0.14.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1) (2019.11.28)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers==2.1) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers==2.1) (2.6.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884629 sha256=41aff4591e9bb18da960804e9a58dda0543cdfdfdcc8c3f72b80b372cebfcc6d\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 transformers-2.1.0\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.1.9)\n",
            "Collecting ftfy==4.4.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/5d/9385540977b00df1f3a0c0f07b7e6c15b5e7a3109d7f6ae78a0a764dab22/ftfy-4.4.3.tar.gz (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.17.5)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.1)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.0.8)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.21.0)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.6/dist-packages (from ftfy==4.4.3) (1.0.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy==4.4.3) (0.1.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.8->spacy) (4.28.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from html5lib->ftfy==4.4.3) (0.5.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from html5lib->ftfy==4.4.3) (1.12.0)\n",
            "Building wheels for collected packages: ftfy\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-4.4.3-cp36-none-any.whl size=41071 sha256=c634bca0b17b996f6a7caaed901742058a772d525c951d7f4a7cf3c5820c1a68\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/54/00/d320239bfc8aad1455314f302dd82a75253fc585e17b81704e\n",
            "Successfully built ftfy\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-4.4.3\n",
            "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxaHPQIG3iVf"
      },
      "source": [
        "# Get data for part-of-speech tagging\n",
        "A probing experiment requires supervised data with linguistic annotation for the property we wish to study. We will use part-of-speech (POS) tagging, a classical problem in NLP. We will use (a portion of) the English Web dependency treebank from the Universal Dependencies project (https://universaldependencies.org/). The dataset comes with POS information, morphological features (tense, gender, number, etc.), and dependency labels (subject, object, etc.), so it can be used to stufy various aspects of language."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0-xo6-q3iVg",
        "outputId": "64e47043-510a-4c53-b291-80757dcd76ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_sentences, train_labels, test_sentences, test_labels, _, _, label2index = get_pos_data(\"/content/tutorial_code/probing\", frac=0.1)\n",
        "# train_sentences, train_labels, test_sentences, test_labels, _, _, label2index = get_pos_data(\"../probing\", frac=0.1)\n",
        "num_labels = len(label2index)\n",
        "print(\"Training sentences:\", len(train_sentences), \"Test sentences:\", len(test_sentences))\n",
        "print(\"Unique labels:\", num_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training sentences: 1254 Test sentences: 208\n",
            "Unique labels: 17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keg_tLaD3iVk"
      },
      "source": [
        "# Set up model\n",
        "A probing experiment also requires a probing model, also known as an auxiliary classifier. Here we define a simple linear classifier, which takes a word representation as input and applies a linear transformation to map it to the label space.\n",
        "\n",
        "We also need a pre-model deep neural network to study. We will use the popular BERT model (https://www.aclweb.org/anthology/N19-1423.pdf), available via the HuggingFace Transformers library (https://huggingface.co/transformers/).  The library provides a number of other models that you can easily experiment with thanks to the unified API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXSLHwPJ3iVl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "efbdc348-ba3b-47b6-a2df-e5abcb7fd3df"
      },
      "source": [
        "class Classifier(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.linear(input)\n",
        "        return output\n",
        "\n",
        "\n",
        "class NonlinearClassifier(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(NonlinearClassifier, self).__init__()\n",
        "\n",
        "        self.input2hidden = torch.nn.Linear(input_dim, input_dim)\n",
        "        self.hidden2output = torch.nn.Linear(input_dim, output_dim)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, input):\n",
        "        hidden = self.relu(self.input2hidden(input))\n",
        "        output = self.hidden2output(hidden)\n",
        "        return output\n",
        "\n",
        "\n",
        "def build_classifier(emb_dim, num_labels, device='cpu'):\n",
        "\n",
        "    classifier = Classifier(emb_dim, num_labels).to(device)\n",
        "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "    optimizer = torch.optim.Adam(classifier.parameters())\n",
        "\n",
        "    return classifier, criterion, optimizer\n",
        "\n",
        "\n",
        "def build_nonlinear_classifier(emb_dim, num_labels, device='cpu'):\n",
        "\n",
        "    classifier = NonlinearClassifier(emb_dim, num_labels).to(device)\n",
        "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "    optimizer = torch.optim.Adam(classifier.parameters())\n",
        "\n",
        "    return classifier, criterion, optimizer\n",
        "\n",
        "\n",
        "model_name = 'bert-base-cased'\n",
        "# get model and tokenizer from Transformers\n",
        "model, tokenizer, sep, emb_dim = get_model_and_tokenizer(model_name, device)\n",
        "# build classifier\n",
        "classifier, criterion, optimizer = build_classifier(emb_dim, num_labels, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:00<00:00, 191512.35B/s]\n",
            "100%|██████████| 435779157/435779157 [00:15<00:00, 28588841.32B/s]\n",
            "100%|██████████| 213450/213450 [00:00<00:00, 835455.57B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuLxynuc3iVp",
        "outputId": "95971146-ea8e-41d8-db1e-a6fdf4df8b88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 768)\n",
            "    (token_type_embeddings): Embedding(2, 768)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (2): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (3): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (4): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (5): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (6): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (7): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (8): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (9): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (10): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (11): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpNO3Ida3iVs",
        "outputId": "5935a884-d9b6-4ce0-b833-8520c01441d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(classifier)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classifier(\n",
            "  (linear): Linear(in_features=768, out_features=17, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KluH35v3iVv"
      },
      "source": [
        "# Train\n",
        "Given a pre-trained model, a probing classifier, and supervised linguistic annotations, we can run a probing experiment. First, we'll define a training function that trains the classifier on the linguistic annotations. This is a simple implementation, but one could implement various checks like early stopping on a development set, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Q_On99u3iVx"
      },
      "source": [
        "def train(num_epochs, train_representations, train_labels,\n",
        "          model, tokenizer, sep, model_name, device,\n",
        "          classifier, criterion, optimizer, batch_size=32):\n",
        "\n",
        "    num_total = train_representations.shape[0]\n",
        "    for i in range(num_epochs):\n",
        "        total_loss = 0.\n",
        "        num_correct = 0.\n",
        "        for batch in range(0, num_total, batch_size):\n",
        "            batch_repr = train_representations[batch: batch+batch_size]\n",
        "            batch_labels = train_labels[batch: batch+batch_size]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            out = classifier(batch_repr)\n",
        "            pred = out.max(1)[1]\n",
        "            num_correct += pred.long().eq(batch_labels.long()).cpu().sum().item()\n",
        "            loss = criterion(out, batch_labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "#         print('Training epoch: {}, loss: {}, accuracy: {}'.format(i, total_loss/num_total, num_correct/num_total))\n",
        "    return total_loss/num_total, num_correct/num_total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y8Rge5S3iV0"
      },
      "source": [
        "# Evaluate\n",
        "Given the trained classifier, we'll evaluate its performance on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi0fG0vg3iV1"
      },
      "source": [
        "def evaluate(test_representations, test_labels,\n",
        "             model, tokenizer, sep, model_name, device,\n",
        "             classifier, criterion, batch_size=32):\n",
        "\n",
        "    num_correct = 0.\n",
        "    num_total = test_representations.shape[0]\n",
        "    total_loss = 0.\n",
        "    with torch.no_grad():\n",
        "        for batch in range(0, num_total, batch_size):\n",
        "            batch_repr = test_representations[batch: batch+batch_size]\n",
        "            batch_labels = test_labels[batch: batch+batch_size]\n",
        "\n",
        "            out = classifier(batch_repr)\n",
        "            pred = out.max(1)[1]\n",
        "            num_correct += pred.long().eq(batch_labels.long()).cpu().sum().item()\n",
        "            total_loss += criterion(out, batch_labels)\n",
        "\n",
        "#     print('Testing loss: {}, accuracy: {}'.format(total_loss/num_total, num_correct/num_total))\n",
        "    return total_loss/num_total, num_correct/num_total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT6l9zXlWv3_"
      },
      "source": [
        "# Generate representations with pretrained model\n",
        "Here we collect representations from the pre-trained model. We also apply a few data transformations for convenience.\n",
        "The end result is `train_sentence_representations`, a list of tensors, where each tensor has representations from one layer in the deep model. Each tensor has dimensions num_word in the corpus x representation dimensionality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsDgYtC2Wv4B"
      },
      "source": [
        "# top-level list: sentences, second-level lists: layers, third-level tensors of num_words x representation_dim\n",
        "train_sentence_representations = [get_sentence_repr(sentence, model, tokenizer, sep, model_name, device)\n",
        "                                  for sentence in train_sentences]\n",
        "test_sentence_representations = [get_sentence_repr(sentence, model, tokenizer, sep, model_name, device)\n",
        "                                  for sentence in test_sentences]\n",
        "\n",
        "# top-level list: layers, second-level lists: sentences\n",
        "train_sentence_representations = [list(l) for l in zip(*train_sentence_representations)]\n",
        "test_sentence_representations = [list(l) for l in zip(*test_sentence_representations)]\n",
        "\n",
        "# concatenate all word represenations\n",
        "train_representations_all = [torch.tensor(np.concatenate(train_layer_representations, 0)).to(device) for train_layer_representations in train_sentence_representations]\n",
        "test_representations_all = [torch.tensor(np.concatenate(test_layer_representations, 0)).to(device) for test_layer_representations in test_sentence_representations]\n",
        "# concatenate all labels\n",
        "train_labels_all = torch.tensor(np.concatenate(train_labels, 0)).to(device)\n",
        "test_labels_all = torch.tensor(np.concatenate(test_labels, 0)).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIBpbUIv3iV4"
      },
      "source": [
        "# Experiment 1: Evaluate representation for POS quality\n",
        "In this experiment, we train and evaluate a classifier on the top-level representations of BERT on the task of POS tagging. The test accuracy can be thought of as a measure of the quality of the representations for the POS property."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-Hsz50R3iV5",
        "outputId": "6e1470d0-7c06-42a2-960f-bcb1bb68d43b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Take final layer representations\n",
        "train_representations = train_representations_all[-1]\n",
        "test_representations = test_representations_all[-1]\n",
        "\n",
        "# train\n",
        "train_loss, train_accuracy = train(10, train_representations, train_labels_all,\n",
        "          model, tokenizer, sep, model_name, device,\n",
        "          classifier, criterion, optimizer)\n",
        "# test\n",
        "test_loss, test_accuracy = evaluate(test_representations, test_labels_all,\n",
        "         model, tokenizer, sep, model_name, device,\n",
        "         classifier, criterion)\n",
        "print(\"Train accuracy: {}, Test accuracy: {}\".format(train_accuracy, test_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 0.9272774422998555, Test accuracy: 0.9177355152587351\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RncHqDF3iV8"
      },
      "source": [
        "# Experiment 2: Compare representation quality across layers\n",
        "One of the major questions in neural network interpretability is how information is organized in different parts of the deep model, such as its layers. Here we train and evaluate a separate classifier per each layer. Notice the test accuracy results for this task, and how deeper is not always better in our case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYqr1lX93iV9",
        "outputId": "5be56df8-f6b3-4459-c79b-ce1a78840baa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "num_layers = len(train_representations_all)\n",
        "train_accs, test_accs = [], []\n",
        "for l in range(num_layers):\n",
        "    # build new classifier for every layer experiment\n",
        "    classifier, criterion, optimizer = build_classifier(emb_dim, num_labels, device)\n",
        "    # get layer representation\n",
        "    train_representations = train_representations_all[l]\n",
        "    test_representations = test_representations_all[l]\n",
        "\n",
        "    # train\n",
        "    train_loss, train_accuracy = train(2, train_representations, train_labels_all,\n",
        "          model, tokenizer, sep, model_name, device,\n",
        "          classifier, criterion, optimizer)\n",
        "    train_accs.append(train_accuracy)\n",
        "    # test\n",
        "    test_loss, test_accuracy = evaluate(test_representations, test_labels_all,\n",
        "         model, tokenizer, sep, model_name, device,\n",
        "         classifier, criterion)\n",
        "    test_accs.append(test_accuracy)\n",
        "    print(\"layer: {}, train accuracy: {}, test accuracy: {}\".format(l, train_accuracy, test_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer: 0, train accuracy: 0.8641499648056904, test accuracy: 0.8474126492702344\n",
            "layer: 1, train accuracy: 0.8840810580520876, test accuracy: 0.8774878372401592\n",
            "layer: 2, train accuracy: 0.9236839180528285, test accuracy: 0.9294559929234851\n",
            "layer: 3, train accuracy: 0.9293891008780054, test accuracy: 0.9294559929234851\n",
            "layer: 4, train accuracy: 0.9329085318415885, test accuracy: 0.9296771340114993\n",
            "layer: 5, train accuracy: 0.932204645648872, test accuracy: 0.9294559929234851\n",
            "layer: 6, train accuracy: 0.9317971325899307, test accuracy: 0.9310039805395842\n",
            "layer: 7, train accuracy: 0.9313896195309895, test accuracy: 0.9279080053073862\n",
            "layer: 8, train accuracy: 0.9243878042455451, test accuracy: 0.9181777974347634\n",
            "layer: 9, train accuracy: 0.9150150038898974, test accuracy: 0.9117647058823529\n",
            "layer: 10, train accuracy: 0.9038639647315971, test accuracy: 0.9035824856258293\n",
            "layer: 11, train accuracy: 0.8942688845256177, test accuracy: 0.8965059708093763\n",
            "layer: 12, train accuracy: 0.8640017782388026, test accuracy: 0.8735072976559045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqkxu9xq3iWB"
      },
      "source": [
        "# Experiment 3: Non-linear classifier\n",
        "Does the probing accuracy depend on the probing model? We have previously trained a linear probing classifier. Here we train a non-linear classifier with one hidden layer. Does the layer-wise pattern change with a different probing model? What does this tell us about the information encoded in the model's internal representations?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sML_JwTh3iWC",
        "outputId": "6237445c-812b-486d-8d5d-b4d2a8ca0c5f",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "num_layers = len(train_representations_all)\n",
        "train_accs, test_accs = [], []\n",
        "for l in range(num_layers):\n",
        "    # build non-linear classifier\n",
        "    classifier, criterion, optimizer = build_nonlinear_classifier(emb_dim, num_labels, device)\n",
        "    # get layer representation\n",
        "    train_representations = train_representations_all[l]\n",
        "    test_representations = test_representations_all[l]\n",
        "\n",
        "    # train\n",
        "    train_loss, train_accuracy = train(2, train_representations, train_labels_all,\n",
        "          model, tokenizer, sep, model_name, device,\n",
        "          classifier, criterion, optimizer)\n",
        "    train_accs.append(train_accuracy)\n",
        "    # test\n",
        "    test_loss, test_accuracy = evaluate(test_representations, test_labels_all,\n",
        "         model, tokenizer, sep, model_name, device,\n",
        "         classifier, criterion)\n",
        "    test_accs.append(test_accuracy)\n",
        "    print(\"layer: {}, train accuracy: {}, test accuracy: {}\".format(l, train_accuracy, test_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer: 0, train accuracy: 0.8708183603156374, test accuracy: 0.8485183547103051\n",
            "layer: 1, train accuracy: 0.8813396065646649, test accuracy: 0.8606811145510835\n",
            "layer: 2, train accuracy: 0.9305005001296632, test accuracy: 0.9279080053073862\n",
            "layer: 3, train accuracy: 0.9367613825806691, test accuracy: 0.9281291463954002\n",
            "layer: 4, train accuracy: 0.9393176008594821, test accuracy: 0.9303405572755418\n",
            "layer: 5, train accuracy: 0.9420960989886267, test accuracy: 0.9281291463954002\n",
            "layer: 6, train accuracy: 0.9442818508502204, test accuracy: 0.9336576735957541\n",
            "layer: 7, train accuracy: 0.9459859963694291, test accuracy: 0.9360902255639098\n",
            "layer: 8, train accuracy: 0.9441336642833327, test accuracy: 0.9307828394515701\n",
            "layer: 9, train accuracy: 0.9365020560886156, test accuracy: 0.9294559929234851\n",
            "layer: 10, train accuracy: 0.92909272774423, test accuracy: 0.9170720919946926\n",
            "layer: 11, train accuracy: 0.9192753676879191, test accuracy: 0.8909774436090225\n",
            "layer: 12, train accuracy: 0.8993072277998, test accuracy: 0.8876603272888103\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wiAVNq0G4ei"
      },
      "source": [
        "# Experiment 4: Control labels\n",
        "\n",
        "In this experiment we test to see how much of the good performance from Experiments 2 and 3 actually come from things the POS model learned, and how much of it just comes from the probe model. To test this, we use a method from Hewitt and Liang (https://arxiv.org/pdf/1909.03368.pdf). We make a <i>control task</i> which is unrelated to the POS task and do the same probing procedure on the control task. We then measure the <i>selectivity</i> of layers; the difference between their probed accuracy on the POS task and on the control task. If a layer has learned substantial things about the POS task in particular, it should be much better at the POS task than the control task; i.e. it should have high selectivity.\n",
        "\n",
        "Following Hewitt and Liang, we use the following control task for POS tagging. Each word identity will be assigned a random POS tag, with the distribution of POS tags weighted according to their actual appearance. Each word identity will always have the same tag every time it appears. We then train and test the layers on predicting this tag from the embedding. Note that this tag is a deterministic function of the word identity, so high selectivity means the embedding actually has forgotten something about the word identity.\n",
        "\n",
        "How are the selectivity results different from the previous accuracy results? What does this tell us about the model's internal representations?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S30miOQ3iWF"
      },
      "source": [
        "import random\n",
        "\n",
        "vocabulary = set(\n",
        "    word\n",
        "      for sentence in (train_sentences + test_sentences)\n",
        "      for word in sentence\n",
        ")\n",
        "# all_labels = sum((x.tolist() for x in train_labels), [])\n",
        "all_labels = train_labels_all.tolist()\n",
        "control_map = {word: random.choice(all_labels) for word in vocabulary}\n",
        "\n",
        "control_train_labels = [torch.tensor([control_map[word] for word in sentence]) for sentence in train_sentences]\n",
        "control_test_labels = [torch.tensor([control_map[word] for word in sentence]) for sentence in test_sentences]\n",
        "control_train_labels = torch.tensor(np.concatenate(control_train_labels, 0)).to(device)\n",
        "control_test_labels = torch.tensor(np.concatenate(control_test_labels, 0)).to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZukN_X9k9_z4",
        "outputId": "08dd50ec-94ff-4901-dd6f-6c846ddab37b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "num_layers = len(train_representations_all)\n",
        "control_train_accs, control_test_accs = [], []\n",
        "for l in range(num_layers):\n",
        "    classifier, criterion, optimizer = build_nonlinear_classifier(emb_dim, num_labels, device)\n",
        "    # get layer representation\n",
        "    train_representations = train_representations_all[l]\n",
        "    test_representations = test_representations_all[l]\n",
        "\n",
        "    # train\n",
        "    train_loss, train_accuracy = train(2, train_representations, control_train_labels,\n",
        "          model, tokenizer, sep, model_name, device,\n",
        "          classifier, criterion, optimizer)\n",
        "    control_train_accs.append(train_accuracy)\n",
        "    # test\n",
        "    test_loss, test_accuracy = evaluate(test_representations, control_test_labels,\n",
        "         model, tokenizer, sep, model_name, device,\n",
        "         classifier, criterion)\n",
        "    control_test_accs.append(test_accuracy)\n",
        "    print(\"layer: {}, train accuracy: {}, test accuracy: {}\".format(l, train_accuracy, test_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer: 0, train accuracy: 0.860223020783166, test accuracy: 0.8951791242812914\n",
            "layer: 1, train accuracy: 0.8554069573593154, test accuracy: 0.8834586466165414\n",
            "layer: 2, train accuracy: 0.8440706849924055, test accuracy: 0.8761609907120743\n",
            "layer: 3, train accuracy: 0.832956692475827, test accuracy: 0.8735072976559045\n",
            "layer: 4, train accuracy: 0.8150631645241359, test accuracy: 0.8509509066784608\n",
            "layer: 5, train accuracy: 0.7936872522505835, test accuracy: 0.8321539141972578\n",
            "layer: 6, train accuracy: 0.769273515355833, test accuracy: 0.8018575851393189\n",
            "layer: 7, train accuracy: 0.7430074463749861, test accuracy: 0.7801857585139319\n",
            "layer: 8, train accuracy: 0.713221946430556, test accuracy: 0.7463511720477665\n",
            "layer: 9, train accuracy: 0.6814359278331419, test accuracy: 0.7016806722689075\n",
            "layer: 10, train accuracy: 0.6490942096098988, test accuracy: 0.6700574966828837\n",
            "layer: 11, train accuracy: 0.6296817693476087, test accuracy: 0.6306943830163645\n",
            "layer: 12, train accuracy: 0.5910421220316379, test accuracy: 0.5946483856700575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9vkW8AFnNL3",
        "outputId": "5448145f-2427-46cf-b44e-25c5462505ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "for l in range(num_layers):\n",
        "    print(\"layer: {}, test selectivity: {}\".format(l, test_accs[l] - control_test_accs[l]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer: 0, test selectivity: -0.046660769570986305\n",
            "layer: 1, test selectivity: -0.02277753206545785\n",
            "layer: 2, test selectivity: 0.051747014595311835\n",
            "layer: 3, test selectivity: 0.054621848739495715\n",
            "layer: 4, test selectivity: 0.07938965059708092\n",
            "layer: 5, test selectivity: 0.09597523219814241\n",
            "layer: 6, test selectivity: 0.1318000884564352\n",
            "layer: 7, test selectivity: 0.15590446704997785\n",
            "layer: 8, test selectivity: 0.18443166740380368\n",
            "layer: 9, test selectivity: 0.22777532065457762\n",
            "layer: 10, test selectivity: 0.24701459531180892\n",
            "layer: 11, test selectivity: 0.26028306059265804\n",
            "layer: 12, test selectivity: 0.29301194161875277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2CBCT-GWv4c"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}